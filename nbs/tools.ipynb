{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vin136/uncertainty-estimates/blob/vin-ideas_1/nbs/tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdd5869-c97a-48a4-9a05-14139e8dd04b",
      "metadata": {
        "id": "5cdd5869-c97a-48a4-9a05-14139e8dd04b"
      },
      "source": [
        "# Tools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a1a83b-e171-4d80-a931-a35b871d4e94",
      "metadata": {
        "id": "e2a1a83b-e171-4d80-a931-a35b871d4e94"
      },
      "source": [
        "## Pytorch-lightning\n",
        "To remove boiler plate code without losing the flexibility of Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e3b03ad4-febd-4053-9264-3e97190b7a27",
      "metadata": {
        "id": "e3b03ad4-febd-4053-9264-3e97190b7a27",
        "outputId": "b94b1a24-fc44-4597-d62e-a2b45abee398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning==1.5.7\n",
            "  Downloading pytorch_lightning-1.5.7-py3-none-any.whl (526 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 102 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 112 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 133 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 143 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 153 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 174 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 184 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 194 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 204 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 215 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 225 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 235 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 256 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 266 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 276 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 286 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 296 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 307 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 317 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 327 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 337 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 348 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 358 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 368 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 378 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 389 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 399 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 409 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 419 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 430 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 440 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 450 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 460 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 471 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 481 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 491 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 501 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 512 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 522 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 526 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.5.7) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.5.7) (1.10.0+cu111)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 29.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.5.7) (4.62.3)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB)\n",
            "\u001b[K     |████████████████████████████████| 332 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.5.7) (21.3)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.5.7) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.5.7) (3.10.0.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.7) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.5.7) (3.0.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (1.42.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.7) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.7) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.7) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.7) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.7) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.5.7) (3.1.1)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.7) (2.0.8)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.7) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 53.4 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 59.0 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=7d3a5684edc3d18c9b99a0e795cd70c3f7feecbe25ba9613ac91b3642764671c\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.7 torchmetrics-0.6.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# To run in colab, on local you should have already installed all the packages.\n",
        "!pip install pytorch-lightning==1.5.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "from matplotlib.colors import to_rgba\n",
        "from tqdm.notebook import tqdm  # Progress bar\n",
        "\n",
        "set_matplotlib_formats(\"svg\", \"pdf\")"
      ],
      "metadata": {
        "id": "ZkEd_SZZoihX"
      },
      "id": "ZkEd_SZZoihX",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)  # Setting the seed"
      ],
      "metadata": {
        "id": "C0zr0VLEpRX1",
        "outputId": "1f9fef05-f519-451e-9ff1-a5e251dd30c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "C0zr0VLEpRX1",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd4f2607ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch-tour"
      ],
      "metadata": {
        "id": "7QsA-QaRpdnN"
      },
      "id": "7QsA-QaRpdnN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensors\n",
        "torch.tensor([2,4,8])"
      ],
      "metadata": {
        "id": "fSOAb4L3ph8R",
        "outputId": "bcd71849-b89e-4257-b714-5c4003a8a680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fSOAb4L3ph8R",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create tensors implicitly\n",
        "torch.arange(0,10,1)\n",
        "torch.zeros(10)\n",
        "torch.randn(2,3)\n",
        "torch.rand(10)"
      ],
      "metadata": {
        "id": "vaXfDzLBqmpf",
        "outputId": "1adde121-7909-47c2-e7c0-fdf49d7b99d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vaXfDzLBqmpf",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1053, 0.2695, 0.3588, 0.1994, 0.5472, 0.0062, 0.9516, 0.0753, 0.8860,\n",
              "        0.5832])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conv btw numpy and torch tensors\n",
        "a = np.array([0,8,7.7])\n",
        "a_t = torch.from_numpy(a)\n",
        "#torch tensor\n",
        "a_t\n",
        "#numpy array - call .cpu before as the original tensor might be on a GPU\n",
        "a_t.cpu().numpy()"
      ],
      "metadata": {
        "id": "xiJyKkCjpXiv",
        "outputId": "c5a2f2d8-1c3a-4cb1-9c3e-f30bba4f834b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xiJyKkCjpXiv",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 8. , 7.7])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting shapes\n",
        "\n",
        "t = torch.rand(4,2,3)\n",
        "t.shape\n",
        "b,r,c = t.size()\n",
        "print(f\"site of tensor : {b,r,c}\")"
      ],
      "metadata": {
        "id": "mD7U9I64ricR",
        "outputId": "212513b9-3bb1-4c98-d836-50fa6add0dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mD7U9I64ricR",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "site of tensor : (4, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# operations on tensors\n",
        "\n",
        "\n",
        "x1 = torch.rand(2)\n",
        "x2 = torch.rand(2)\n",
        "#creates new tensor\n",
        "x1+x2"
      ],
      "metadata": {
        "id": "y5f9pNfusY0h",
        "outputId": "d0486eae-4169-4a5d-bfb5-d08d2d6706fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y5f9pNfusY0h",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7498, 0.3936])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inplace ops\n",
        "print(f\"x1 before:{x1}\")\n",
        "print(f\"x2 before:{x2}\")\n",
        "x1.add_(x2)\n",
        "print(f\"x1 after:{x1}\")\n",
        "print(f\"x2 after:{x2}\")"
      ],
      "metadata": {
        "id": "mGUpVk_Esxo1",
        "outputId": "1a355004-a97a-458f-935d-dab29e89f685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mGUpVk_Esxo1",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 before:tensor([0.1716, 0.3336])\n",
            "x2 before:tensor([0.5782, 0.0600])\n",
            "x1 after:tensor([0.7498, 0.3936])\n",
            "x2 after:tensor([0.5782, 0.0600])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape ops\n",
        "\n",
        "x = torch.rand(1,2,4)\n",
        "x.view(8)"
      ],
      "metadata": {
        "id": "bGn-5-yetGDQ",
        "outputId": "d14f1d30-252e-4162-ccab-7e372726138c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bGn-5-yetGDQ",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3289, 0.1054, 0.9192, 0.4008, 0.9302, 0.6558, 0.0766, 0.8460])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.permute([1,0,2])\n",
        "y.shape"
      ],
      "metadata": {
        "id": "oeKeXd5-tUK8",
        "outputId": "4fb118f3-4628-46fc-cf02-ae2553fd27b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oeKeXd5-tUK8",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix multiplication with broadcasting.\n",
        "\n",
        "x = torch.tensor([1.0,2.0,3.0]).view(3,1)\n",
        "W = torch.rand(2,3)\n",
        "print(x.shape,W.shape)"
      ],
      "metadata": {
        "id": "NHUo7KNItxxY",
        "outputId": "ff6e6bf1-3da6-48e8-e94d-e995c5f4cb72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NHUo7KNItxxY",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1]) torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(W,x)"
      ],
      "metadata": {
        "id": "Edy9H3O4uKJW",
        "outputId": "2870b7d7-76a2-4d47-9a8f-3fef90864186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Edy9H3O4uKJW",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.4876],\n",
              "        [2.7736]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W@x"
      ],
      "metadata": {
        "id": "jMsbG6fPuOvB",
        "outputId": "36ee76bc-69e9-4615-8098-77f22b13e070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jMsbG6fPuOvB",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.4876],\n",
              "        [2.7736]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradients\n",
        "x = torch.ones((2,))\n",
        "x.requires_grad"
      ],
      "metadata": {
        "id": "OK_6HXoNvmge",
        "outputId": "d8935d49-d136-44e4-9993-730c4fb415c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OK_6HXoNvmge",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we need grad w.r.t this variable\n",
        "x.requires_grad_(True)\n",
        "x.requires_grad"
      ],
      "metadata": {
        "id": "VqEBWGYxweXR",
        "outputId": "5f9c8898-e30b-43c3-d63e-34a8ec150e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VqEBWGYxweXR",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic computation graphs\n",
        "\n",
        "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$.\n",
        "For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$.\n",
        "For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
      ],
      "metadata": {
        "id": "4EKu2ZKbxAZ2"
      },
      "id": "4EKu2ZKbxAZ2"
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3,dtype=torch.float32,requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "id": "nM3_LVksxCJj",
        "outputId": "d9c3405e-d14f-4803-a3ce-9c315754e30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nM3_LVksxCJj",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = x+2\n",
        "b = a**2\n",
        "c = b+3\n",
        "y = c.mean()\n",
        "y"
      ],
      "metadata": {
        "id": "8ZzFncPtxUCX",
        "outputId": "52af54ed-c8ee-41a3-cb9e-13edd878f357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8ZzFncPtxUCX",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12.6667, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "print(x.grad.data)"
      ],
      "metadata": {
        "id": "L246IFbiyVF_",
        "outputId": "83141813-fd68-45ca-d535-2b0ab4fee2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L246IFbiyVF_",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3333, 2.0000, 2.6667])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_S_r0XTe1Gw_"
      },
      "id": "_S_r0XTe1Gw_"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cbhkg9rnyv0P"
      },
      "id": "cbhkg9rnyv0P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also verify these gradients by hand.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We will calculate the gradients using the chain rule, in the same way as PyTorch did it:\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
        "\n",
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor.\n",
        "The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$.\n",
        "The previous code cell should have printed the same result."
      ],
      "metadata": {
        "id": "MiqgHyXhyZrC"
      },
      "id": "MiqgHyXhyZrC"
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU's\n",
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "Cz8nADwFyaYk",
        "outputId": "19e3109e-e593-4bc4-bc3f-d3c7bf99697f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cz8nADwFyaYk",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#specify device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)\n",
        "\n",
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "GOqA9jfSzDB8",
        "outputId": "ffb0dcfb-157c-406b-beff-7cdb221121c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GOqA9jfSzDB8",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n",
            "X tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu speed-up\n",
        "x = torch.randn(10000, 10000)\n",
        "\n",
        "# CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "# GPU version\n",
        "if torch.cuda.is_available():\n",
        "    x = x.to(device)\n",
        "    # CUDA is asynchronous, so we need to use different timing functions\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    start.record()\n",
        "    _ = torch.matmul(x, x)\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "    print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "DFBKejiwzhg6",
        "outputId": "ed27e680-ed69-453f-83dc-c153c91d7f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DFBKejiwzhg6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 26.72527s\n",
            "GPU time: 0.92781s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU operations have a separate seed we also want to set\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "aSS_3Vr3wzPj"
      },
      "id": "aSS_3Vr3wzPj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lightning-tour"
      ],
      "metadata": {
        "id": "cnINbsuA38b7"
      },
      "id": "cnINbsuA38b7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get straight into how to build models using pytorch-lightning\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zaS6jEX-0TvO"
      },
      "id": "zaS6jEX-0TvO",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eKrKmelnw-qN"
      },
      "id": "eKrKmelnw-qN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TfJ-9ihbpb6E"
      },
      "id": "TfJ-9ihbpb6E"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VXNJlJ16o29-"
      },
      "id": "VXNJlJ16o29-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "name": "tools.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}